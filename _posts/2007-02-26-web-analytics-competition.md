---
id: 44
title: Web Analytics Competition
date: 2007-02-26T18:39:20-07:00
author: Ben
layout: post
guid: http://benrobb.com/2007/02/26/web-analytics-competition/
permalink: /2007/02/26/web-analytics-competition/
dsq_thread_id:
  - "3051384275"
categories:
  - Old Stuff
---
I suppose I've probably mentioned this before, but Omniture is sponsoring a web analytics competition at Brigham Young University.  I'm happy to announce that after a weekend of stewing my group was just informed that we've made it into the finals.  Of the 40 or so teams that signed up originally, they've selected 4 to go into the finals.  We just found out and the finals are only 3 days away.

There isn't a whole lot I can say about the specifics of the project, but it was interesting to note the things that we did well and the things that we didn't do so well on.

<strong>Observation #1</strong>
We began our presentation by identifying a business goal for the client's web site.  What is it that they're trying to accomplish with the site?  We then broke that objective down into a few success events that would demonstrate that the site's users were progressing towards the end goal we had identified.  Then we explained a few key performance indicators that would measure the customer's progress towards these success events and goals.

For this particular client, their web site was a sales site and the objective was obviously to generate revenue (orders, etc).  Our problem was that we started by stating <em>revenue</em> as the objective and spent the rest of the presentation talking about how to increase <em>orders</em> without going back to revenue.

I suppose that picking one and staying consistent would satisfice, but for a site that generates revenue, I think it wisest to phrase everything in those terms.

<strong>Observation #2</strong>
We weren't as careful as we should have been in our use of terms.  For example we used the phrase "conversion rate" a bit loosely and got called on it in the Q/A section of our presentation.  We presented the conversion rate in terms of what percentage of overall orders each search term was responsible for when in reality the conversion rate should have been expressed as Orders/Search.  Or perhaps even better, as Revenue/Search.

Our efforts to explain our meaning in the Q/A part following our presentation I think missed the mark, so we need to go back and make sure that what we say is getting the proper meaning across.

I suppose the wrap-up to this little stream of consciousness is that in data-driven analytics you've got to be specific, you've got to be consistent, and you've got to ask the right questions.